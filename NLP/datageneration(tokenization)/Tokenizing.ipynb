{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EN_WHITELIST = '0123456789abcdefghijklmnopqrstuvwxyz ' # space is included in whitelist\n",
    "EN_BLACKLIST = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILENAME = 'shakespeare.txt'\n",
    "\n",
    "VOCAB_SIZE = 16000\n",
    "\n",
    "SEQ_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    " read lines from file\n",
    "     return [list of lines]\n",
    "'''\n",
    "def read_lines(filename):\n",
    "    content = ''\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                if not line.strip()[-1] == ':':\n",
    "                    content += line\n",
    "    return content.split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    " split sentences in one line\n",
    "  into multiple lines\n",
    "    return [list of lines]\n",
    "'''\n",
    "def split_line(line):\n",
    "    return line.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    " remove anything that isn't in the vocabulary\n",
    "    return str(pure ta/en)\n",
    "'''\n",
    "def filter_line(line, whitelist):\n",
    "    return ''.join([ ch for ch in line if ch in whitelist ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    " read list of words, create index to word,\n",
    "  word to index dictionaries\n",
    "    return tuple( vocab->(word, count), idx2w, w2idx )\n",
    "'''\n",
    "def index_(tokenized_sentences, vocab_size):\n",
    "    # get frequency distribution\n",
    "    freq_dist = nltk.FreqDist(tokenized_sentences)\n",
    "    # get vocabulary of 'vocab_size' most used words\n",
    "    vocab = freq_dist.most_common(vocab_size)\n",
    "    # index2word\n",
    "    index2word = [ x[0] for x in vocab ]\n",
    "    # word2index\n",
    "    word2index = dict([(w,i) for i,w in enumerate(index2word)] )\n",
    "    return index2word, word2index, freq_dist\n",
    "\n",
    "\n",
    "def to_array(tokenized, seqlen, w2idx):\n",
    "    num_words = len(tokenized)\n",
    "    # calc data_len\n",
    "    data_len = num_words//seqlen\n",
    "    # create numpy arrays\n",
    "    X = np.zeros([data_len, seqlen])\n",
    "    Y = np.zeros([data_len, seqlen])\n",
    "    # fill in\n",
    "    for i in range(data_len):\n",
    "        X[i] = np.array([ w2idx[w] for w in tokenized[i*seqlen:(i+1)*seqlen] ])\n",
    "        Y[i] = np.array([ w2idx[w] for w in tokenized[(i*seqlen) + 1 : ((i+1)*seqlen) + 1] ])\n",
    "    # return ndarrays\n",
    "    return X.astype(np.int32), Y.astype(np.int32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Read lines from file\n"
     ]
    }
   ],
   "source": [
    "print('\\n>> Read lines from file')\n",
    "lines = read_lines(filename=FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before we proceed any further, hear me speak.',\n",
       " 'Speak, speak.',\n",
       " 'You are all resolved rather to die than to famish?',\n",
       " 'Resolved. resolved.',\n",
       " 'First, you know Caius Marcius is chief enemy to the people.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['before we proceed any further, hear me speak.',\n",
       " 'speak, speak.',\n",
       " 'you are all resolved rather to die than to famish?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change to lower case (just for en)\n",
    "lines = [ line.lower() for line in lines ]\n",
    "lines[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ":: Sample from read(p) lines\n",
      "\n",
      "[\"'that i receive the general food at first,\", 'which you do live upon; and fit it is,', 'because i am the store-house and the shop', 'of the whole body: but, if you do remember,']\n"
     ]
    }
   ],
   "source": [
    "print('\\n:: Sample from read(p) lines\\n')\n",
    "print(lines[121:125])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Filter lines\n",
      "\n",
      "['that i receive the general food at first', 'which you do live upon and fit it is', 'because i am the storehouse and the shop', 'of the whole body but if you do remember']\n"
     ]
    }
   ],
   "source": [
    " # filter out unnecessary characters\n",
    "print('\\n>> Filter lines\\n')\n",
    "lines = [ filter_line(line, EN_WHITELIST) for line in lines ]\n",
    "print(lines[121:125])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Segment lines into words\n",
      "\n",
      "\n",
      ":: Sample from segmented list of words\n",
      "\n",
      "['away', 'away', 'one', 'word', 'good', 'citizens', 'we', 'are', 'accounted', 'poor']\n"
     ]
    }
   ],
   "source": [
    "# convert list of [lines of text] into list of [list of words ]\n",
    "print('\\n>> Segment lines into words\\n')\n",
    "tokenized = [ w for wordlist in lines for w in wordlist.split(' ') ]\n",
    "print('\\n:: Sample from segmented list of words\\n')\n",
    "print(tokenized[60:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> Index words\n"
     ]
    }
   ],
   "source": [
    "# indexing -> idx2w, w2idx : en/ta\n",
    "print('\\n >> Index words')\n",
    "idx2w, w2idx, freq_dist = index_( tokenized, vocab_size=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12506"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12506"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove unknowns\n",
    "tokenized = [ w for w in tokenized if w in idx2w ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to ndarray\n",
    "X, Y = to_array(tokenized, SEQ_LEN, w2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129,  32, 953, 124, 582, 110,  15, 101, 101, 101])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32, 953, 124, 582, 110,  15, 101, 101, 101,   5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resolved resolved first you know caius marcius is chief enemy'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([idx2w[i] for i in X[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resolved first you know caius marcius is chief enemy to'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([idx2w[i] for i in Y[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >> Save numpy arrays to disk\n"
     ]
    }
   ],
   "source": [
    "print('\\n >> Save numpy arrays to disk')\n",
    "# save them\n",
    "np.save('idx_x.npy', X)\n",
    "np.save('idx_y.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let us now save the necessary dictionaries\n",
    "metadata = {\n",
    "            'w2idx' : w2idx,\n",
    "            'idx2w' : idx2w,\n",
    "            'seqlen' : SEQ_LEN,\n",
    "            'freq_dist' : freq_dist\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # write to disk : data control dictionaries\n",
    "with open('metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(PATH=''):\n",
    "    # read data control dictionaries\n",
    "    with open(PATH + 'metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    # read numpy arrays\n",
    "    idx_x = np.load(PATH + 'idx_x.npy')\n",
    "    idx_y = np.load(PATH + 'idx_y.npy')\n",
    "    return idx_x, idx_y, metadata['idx2w'], metadata['w2idx'], metadata['seqlen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y, idx2w, w2idx, seqlen = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18087, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18087, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2w[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12506"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
